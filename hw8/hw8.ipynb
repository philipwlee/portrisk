{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad08ba8-bde1-475f-9bc3-7db530a83b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (16,10)\n",
    "plt.style.use(\"~/.dracula.mplstyle\")\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385622c8-465b-44f0-990a-096352f1db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in <ltcm.xlsx>.\n",
      "-------------------- Reading Sheets  --------------------\n",
      "Sheet 0: Copyright; shape=(4, 1)\n",
      "Sheet 1: Exhibit 2; shape=(60, 5)\n",
      "Sheet 2: Exhibit 4; shape=(54, 5)\n",
      "-------------------- Setting Indices --------------------\n",
      "-------------------- Checking Nulls  --------------------\n",
      "Null values found in <1>. Dropping.\n",
      "Null values found in <2>. Dropping.\n",
      "\n",
      "\n",
      "\n",
      "Read in <gmo.xlsx>.\n",
      "-------------------- Reading Sheets  --------------------\n",
      "Sheet 0: descriptions; shape=(6, 4)\n",
      "Sheet 1: signals; shape=(345, 4)\n",
      "Sheet 2: returns (total); shape=(345, 3)\n",
      "Sheet 3: risk-free rate; shape=(345, 2)\n",
      "-------------------- Setting Indices --------------------\n",
      "-------------------- Checking Nulls  --------------------\n",
      "No nulls found :)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fund_cap</th>\n",
       "      <th>gross</th>\n",
       "      <th>net</th>\n",
       "      <th>cumulative</th>\n",
       "      <th>SPY</th>\n",
       "      <th>US3M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994-03-01</th>\n",
       "      <td>1.1000</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>-0.0160</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>-0.0449</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-01</th>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-01</th>\n",
       "      <td>1.2000</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>1.0500</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-01</th>\n",
       "      <td>1.2000</td>\n",
       "      <td>-0.0425</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>1.0200</td>\n",
       "      <td>-0.0264</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-01</th>\n",
       "      <td>1.4000</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fund_cap   gross     net  cumulative     SPY   US3M\n",
       "date                                                           \n",
       "1994-03-01    1.1000 -0.0140 -0.0160      0.9900 -0.0449 0.0030\n",
       "1994-04-01    1.1000  0.0107  0.0047      1.0000  0.0079 0.0033\n",
       "1994-05-01    1.2000  0.0644  0.0494      1.0500  0.0123 0.0036\n",
       "1994-06-01    1.2000 -0.0425 -0.0326      1.0200 -0.0264 0.0036\n",
       "1994-07-01    1.4000  0.1123  0.0803      1.1000  0.0287 0.0037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DataImport:\n",
    "    \n",
    "    def __init__(self, filename, add_ind=[], na_method=\"interpolate\"):\n",
    "        self.xlsx = pd.ExcelFile(filename)\n",
    "        self.add_ind = add_ind # Additional indices to try to \n",
    "        \n",
    "        print(f\"Read in <{filename}>.\")\n",
    "        self.sheets = []\n",
    "        print('-'*20, \"Reading Sheets \", '-'*20)\n",
    "        self.read_sheets()\n",
    "        print('-'*20, \"Setting Indices\", '-'*20)\n",
    "        self.set_indices()\n",
    "        print('-'*20, \"Checking Nulls \", '-'*20)\n",
    "        self.check_nulls(na_method)\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    def read_sheets(self):\n",
    "        for i, s in enumerate(self.xlsx.sheet_names):\n",
    "            read_sheet = self.xlsx.parse(s)\n",
    "            print(f\"Sheet {i}: {s}; shape={read_sheet.shape}\")\n",
    "            self.sheets.append(read_sheet)\n",
    "    \n",
    "    def set_indices(self):\n",
    "        for s in self.sheets:\n",
    "            for d in [\"date\", \"Date\", \"DATE\", \"Unnamed: 0\"]+self.add_ind:\n",
    "                try:\n",
    "                    s.set_index(d, inplace=True) # Date as index\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    def check_nulls(self, method):\n",
    "        n = 0\n",
    "        for i, s in enumerate(self.sheets[1:]):\n",
    "            has_nulls = True\n",
    "            while has_nulls:\n",
    "                if sum(s.isna().sum())==0: # Check for nulls\n",
    "                    has_nulls = False\n",
    "                else:\n",
    "                    if method==\"interpolate\":\n",
    "                        print(f\"Null values found in <{i+1}>. Interpolating linearly.\")\n",
    "                        s = s.interpolate() # Linerly interpolate nulls\n",
    "                        self.sheets[i+1] = s\n",
    "                    elif method==\"drop\":\n",
    "                        print(f\"Null values found in <{i+1}>. Dropping.\")\n",
    "                        s = s.dropna()\n",
    "                        self.sheets[i+1] = s\n",
    "                    elif method==\"none\":\n",
    "                        break\n",
    "                    n += 1\n",
    "                if n>i+1:\n",
    "                    print(\"Something broke...\")\n",
    "                    n=i+1\n",
    "                    break\n",
    "        if n==0: print(\"No nulls found :)\")\n",
    "\n",
    "ltcm = DataImport(\"ltcm.xlsx\", na_method=\"drop\")\n",
    "# display(ltcm.sheets[0])\n",
    "ex2 = ltcm.sheets[1]\n",
    "mapper = {\n",
    "    \"Exhibit 2     Fund Capital and Monthly Returns (June, 1994 to July, 1998)\": \"date\",\n",
    "    \"Unnamed: 1\": \"fund_cap\",\n",
    "    \"Unnamed: 2\": \"gross\",\n",
    "    \"Unnamed: 3\": \"net\",\n",
    "    \"Unnamed: 4\": \"cumulative\",\n",
    "}\n",
    "ex2.rename(columns=mapper, inplace=True)\n",
    "ex2.set_index(\"date\", inplace=True)\n",
    "for c in ex2.columns:\n",
    "    ex2[c] = pd.to_numeric(ex2[c])\n",
    "\n",
    "gmo = DataImport(\"gmo.xlsx\", na_method=\"none\")\n",
    "# display(gmo.sheets[0])\n",
    "gmo.sheets[2].index += pd.DateOffset(1)\n",
    "gmo.sheets[3].index += pd.DateOffset(1)\n",
    "gmo.sheets[2].index += pd.DateOffset(months=-1)\n",
    "gmo.sheets[3].index += pd.DateOffset(months=-1)\n",
    "ex2 = ex2.join(gmo.sheets[2][\"SPY\"])\n",
    "ex2 = ex2.join(gmo.sheets[3][\"US3M\"])\n",
    "ex2[[\"gross\", \"net\", \"SPY\"]] = ex2[[\"gross\", \"net\", \"SPY\"]].subtract(ex2[\"US3M\"], axis=0)\n",
    "\n",
    "display(ex2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda70f9-43a1-496a-bd2c-3aaa4ec19886",
   "metadata": {},
   "source": [
    "# 2. LTCM Risk Decomposition\n",
    "\n",
    "On Canvas, find the data file, “ltcm exhibits data.xlsx”. Get the gross and net (total) returns of LTCM from “Exhibit 2”.\n",
    "\n",
    "Get the returns on SPY as well as the risk-free rate from the file, “gmo analysis data”.\n",
    "\n",
    "#### 1. Summary stats.\n",
    "\n",
    "(a) For both the gross and net series of LTCM excess returns, report the mean, volatility, and Sharpe ratios. (Annualize them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e82233-9266-46e3-9649-b0ad899d39e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1994-1998</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Vol</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.1738</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>1.5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gross</th>\n",
       "      <td>0.2421</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>1.7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net</th>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>1.3901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year     1994-1998              \n",
       "measure       Mean    Vol Sharpe\n",
       "variable                        \n",
       "SPY         0.1738 0.1123 1.5479\n",
       "gross       0.2421 0.1362 1.7769\n",
       "net         0.1554 0.1118 1.3901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pivot_summaries(data, year_mask=None, pi=0.05, nper=12):\n",
    "    if not(year_mask):\n",
    "        year_mask = [(str(min(data.index).year), str(max(data.index).year))]\n",
    "    \n",
    "    data_melt = pd.melt(data, ignore_index=False).sort_index()\n",
    "    \n",
    "    pivlist = []\n",
    "    for start, end in year_mask:\n",
    "        def me(x): return nper * np.mean(x)\n",
    "        def sd(x): return np.sqrt(nper) * np.std(x, ddof=1) # account for degrees of freedom\n",
    "        def sr(x): return np.sqrt(nper) * np.mean(x) / np.std(x, ddof=1)\n",
    "        af = [me, sd, sr]\n",
    "        af_names = [\"Mean\", \"Vol\", \"Sharpe\"]\n",
    "        \n",
    "        piv = pd.pivot_table(data_melt[start:end], index=\"variable\", values=\"value\",\n",
    "                             aggfunc=af)\n",
    "        piv.columns = pd.MultiIndex.from_arrays([[f\"{start}-{end}\"] * len(af), af_names],\n",
    "                                                names=[\"year\", \"measure\"])\n",
    "        pivlist.append(piv)\n",
    "\n",
    "    summ = pd.concat(pivlist, axis=1)\n",
    "    return summ\n",
    "\n",
    "ps = pivot_summaries(ex2[[\"gross\", \"net\", \"SPY\"]])\n",
    "display(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2964f5fd-e10c-48a0-90b3-3d869e413bec",
   "metadata": {},
   "source": [
    "(b) Report the skewness, kurtosis, and (historic) VaR(.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2633fac0-572d-474a-8ad2-045efa57e7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>var_0.05</th>\n",
       "      <th>cvar_0.05</th>\n",
       "      <th>drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gross</th>\n",
       "      <td>-0.1053</td>\n",
       "      <td>-0.2877</td>\n",
       "      <td>1.5866</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>-0.0730</td>\n",
       "      <td>-0.1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net</th>\n",
       "      <td>-0.1053</td>\n",
       "      <td>-0.8102</td>\n",
       "      <td>2.9269</td>\n",
       "      <td>-0.0264</td>\n",
       "      <td>-0.0687</td>\n",
       "      <td>-0.1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>-0.0562</td>\n",
       "      <td>-0.4335</td>\n",
       "      <td>-0.3620</td>\n",
       "      <td>-0.0464</td>\n",
       "      <td>-0.0514</td>\n",
       "      <td>-0.0562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min    skew  kurtosis  var_0.05  cvar_0.05  drawdown\n",
       "gross -0.1053 -0.2877    1.5866   -0.0304    -0.0730   -0.1689\n",
       "net   -0.1053 -0.8102    2.9269   -0.0264    -0.0687   -0.1761\n",
       "SPY   -0.0562 -0.4335   -0.3620   -0.0464    -0.0514   -0.0562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tailrisk(v, prob, logret=False, exkurt=True):\n",
    "    \"\"\"Arguments:\n",
    "    v: pd.DataFrame containing columns of returns\n",
    "    prob: float percentile for VaR\n",
    "    excess: bool whether kurtosis of normal = 0 (True) or = 3 (False)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = v.columns\n",
    "    except AttributeError:\n",
    "        c = [\"Portfolio\"]\n",
    "    \n",
    "    mi = v.min()\n",
    "    sk = v.skew()\n",
    "    ku = v.kurtosis() - 3 * exkurt\n",
    "    var = v.quantile(prob)\n",
    "    \n",
    "    cvar = []\n",
    "    mask =  v < var\n",
    "    for name, col in mask.iteritems():\n",
    "        below = v[name].loc[col]\n",
    "        cvar.append(sum(below)/len(below))\n",
    "    \n",
    "    cvar = pd.Series(cvar, index=c)\n",
    "    \n",
    "    if logret:\n",
    "        cumu = np.exp(v.cumsum())\n",
    "    else:\n",
    "        cumu = (v+1).cumprod()\n",
    "    from_peak = (cumu - cumu.cummax()) / cumu.cummax()\n",
    "\n",
    "    pl, rl, dl = [], [], []\n",
    "    trough = from_peak.idxmin()\n",
    "    for col, date in trough.iteritems():\n",
    "        peak = max(v.loc[(from_peak.index < date) & (from_peak[col] == 0), col].index)\n",
    "        try:\n",
    "            reco = min(v.loc[(from_peak.index > date) & (from_peak[col] == 0), col].index)\n",
    "        except ValueError:\n",
    "            reco = None\n",
    "        \n",
    "        if logret:\n",
    "            # This may not work right at the moment...\n",
    "            draw = np.log(cumu.loc[date,col] / cumu.loc[peak,col])\n",
    "        else:\n",
    "            draw = (cumu.loc[date,col] - cumu.loc[peak,col]) / cumu.loc[peak,col]\n",
    "\n",
    "        pl.append(peak); rl.append(reco); dl.append(draw)\n",
    "\n",
    "    dl = pd.Series(dl, index=c)\n",
    "    pl = pd.Series(pl, index=c)\n",
    "    rl = pd.Series(rl, index=c)\n",
    "    \n",
    "    ret = pd.DataFrame([mi, sk, ku, var, cvar, dl],\n",
    "                       index=[\"min\", \"skew\", \"kurtosis\", f\"var_{prob}\", f\"cvar_{prob}\", \"drawdown\"],\n",
    "                       columns=c)\n",
    "    dra = pd.DataFrame([pl, trough, rl],\n",
    "                       index=[\"peak\", \"trough\", \"recovery\"],\n",
    "                       columns=c)\n",
    "    ret = pd.concat([ret], axis=0).T\n",
    "    \n",
    "    return ret\n",
    "\n",
    "tr = tailrisk(ex2[[\"gross\", \"net\", \"SPY\"]], 0.05, logret=False, exkurt=False)\n",
    "\n",
    "display(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364ec93-a33b-4742-b4d6-82b12a17c98b",
   "metadata": {},
   "source": [
    "(c) Comment on how these stats compare to SPY and other assets we have seen. How much do they differ between gross and net?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646c992-aa27-443a-8cd3-2e4f0d126f52",
   "metadata": {},
   "source": [
    "#### 2. Using the series of net LTCM excess returns, denoted r ̃, estimate the following regression:\n",
    "\n",
    "(a) Report α and βm. Report the R2 stat.\n",
    "\n",
    "(b) From this regression, does LTCM appear to be a “closet indexer”?\n",
    "\n",
    "pass\n",
    "\n",
    "(c) From the regression, does LTCM appear to deliver excess returns beyond the risk premium we expect from market exposure?\n",
    "\n",
    "yes alpha pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3016ee7-22d4-432e-948e-460503bec6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plee/miniconda3/envs/finmath/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>net</td>       <th>  R-squared:         </th> <td>   0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.9866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.325</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:52:46</td>     <th>  Log-Likelihood:    </th> <td>  107.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    53</td>      <th>  AIC:               </th> <td>  -211.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    51</td>      <th>  BIC:               </th> <td>  -207.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0110</td> <td>    0.005</td> <td>    2.254</td> <td> 0.029</td> <td>    0.001</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPY</th>   <td>    0.1371</td> <td>    0.138</td> <td>    0.993</td> <td> 0.325</td> <td>   -0.140</td> <td>    0.414</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.910</td> <th>  Durbin-Watson:     </th> <td>   1.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  25.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.838</td> <th>  Prob(JB):          </th> <td>3.22e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.940</td> <th>  Cond. No.          </th> <td>    31.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    net   R-squared:                       0.019\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.9866\n",
       "Date:                Sun, 05 Dec 2021   Prob (F-statistic):              0.325\n",
       "Time:                        23:52:46   Log-Likelihood:                 107.80\n",
       "No. Observations:                  53   AIC:                            -211.6\n",
       "Df Residuals:                      51   BIC:                            -207.7\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0110      0.005      2.254      0.029       0.001       0.021\n",
       "SPY            0.1371      0.138      0.993      0.325      -0.140       0.414\n",
       "==============================================================================\n",
       "Omnibus:                       14.910   Durbin-Watson:                   1.810\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               25.291\n",
       "Skew:                          -0.838   Prob(JB):                     3.22e-06\n",
       "Kurtosis:                       5.940   Cond. No.                         31.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = sm.OLS(ex2[\"net\"], sm.add_constant(ex2[\"SPY\"])).fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e091b-9b57-49f8-94b1-845d0a6cf7ba",
   "metadata": {},
   "source": [
    "#### 3. Let’s check for non-linear market exposure. Run the following regression on LTCM’s net excess returns:\n",
    "\n",
    "(a) Report β1, β2, and the R2 stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee83048-d2f5-4959-af8d-c8dd96a3ec35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>net</td>       <th>  R-squared:         </th> <td>   0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.6232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.540</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:52:46</td>     <th>  Log-Likelihood:    </th> <td>  107.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    53</td>      <th>  AIC:               </th> <td>  -209.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    50</td>      <th>  BIC:               </th> <td>  -204.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>    0.0129</td> <td>    0.006</td> <td>    2.096</td> <td> 0.041</td> <td>    0.001</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPY</th>    <td>    0.1669</td> <td>    0.150</td> <td>    1.111</td> <td> 0.272</td> <td>   -0.135</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPY_SQ</th> <td>   -1.9267</td> <td>    3.682</td> <td>   -0.523</td> <td> 0.603</td> <td>   -9.323</td> <td>    5.469</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.616</td> <th>  Durbin-Watson:     </th> <td>   1.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  26.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.880</td> <th>  Prob(JB):          </th> <td>1.55e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.004</td> <th>  Cond. No.          </th> <td>    825.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    net   R-squared:                       0.024\n",
       "Model:                            OLS   Adj. R-squared:                 -0.015\n",
       "Method:                 Least Squares   F-statistic:                    0.6232\n",
       "Date:                Sun, 05 Dec 2021   Prob (F-statistic):              0.540\n",
       "Time:                        23:52:46   Log-Likelihood:                 107.95\n",
       "No. Observations:                  53   AIC:                            -209.9\n",
       "Df Residuals:                      50   BIC:                            -204.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0129      0.006      2.096      0.041       0.001       0.025\n",
       "SPY            0.1669      0.150      1.111      0.272      -0.135       0.469\n",
       "SPY_SQ        -1.9267      3.682     -0.523      0.603      -9.323       5.469\n",
       "==============================================================================\n",
       "Omnibus:                       15.616   Durbin-Watson:                   1.866\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.759\n",
       "Skew:                          -0.880   Prob(JB):                     1.55e-06\n",
       "Kurtosis:                       6.004   Cond. No.                         825.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exo = pd.concat([pd.Series(np.ones(len(ex2)), name=\"const\", index=ex2.index), ex2[\"SPY\"],\n",
    "                 (ex2[\"SPY\"]**2).rename(\"SPY_SQ\")], axis=1)\n",
    "\n",
    "res = sm.OLS(ex2[\"net\"], exo).fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb48eda-ed32-417b-878f-1f5f496cb9c8",
   "metadata": {},
   "source": [
    "(b) Does the quadratic market factor do much to increase the overall LTCM variation explained by the market?\n",
    "\n",
    "pass\n",
    "\n",
    "(c) From the regression evidence, does LTCM’s market exposure behave as if it is long market options or short market options?\n",
    "\n",
    "short market put: positive delta, negative gamma\n",
    "\n",
    "(d) Should we describe LTCM as being positively or negatively exposed to market volatility?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59e561-89a5-4046-8cda-b9f26cc1b6e8",
   "metadata": {},
   "source": [
    "#### 4. Let’s try to pinpoint the nature of LTCM’s nonlinear exposure. Does it come more from exposure to up-markets or down-markets? Run the following regression on LTCM’s net excess returns:\n",
    "\n",
    "(a) Report β, βu, βd, and the R2 stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444f28ea-bc89-4c01-88b3-799eacbde653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>net</td>       <th>  R-squared:         </th> <td>   0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.9595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.419</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:52:46</td>     <th>  Log-Likelihood:    </th> <td>  108.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    53</td>      <th>  AIC:               </th> <td>  -209.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    49</td>      <th>  BIC:               </th> <td>  -201.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    0.0084</td> <td>    0.006</td> <td>    1.417</td> <td> 0.163</td> <td>   -0.004</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPY</th>      <td>    0.4666</td> <td>    0.277</td> <td>    1.687</td> <td> 0.098</td> <td>   -0.089</td> <td>    1.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPY_UP</th>   <td>   -0.7821</td> <td>    0.629</td> <td>   -1.244</td> <td> 0.219</td> <td>   -2.045</td> <td>    0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPY_DOWN</th> <td>    1.2896</td> <td>    1.157</td> <td>    1.115</td> <td> 0.270</td> <td>   -1.036</td> <td>    3.615</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18.184</td> <th>  Durbin-Watson:     </th> <td>   1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  35.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.980</td> <th>  Prob(JB):          </th> <td>2.30e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.477</td> <th>  Cond. No.          </th> <td>    276.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    net   R-squared:                       0.055\n",
       "Model:                            OLS   Adj. R-squared:                 -0.002\n",
       "Method:                 Least Squares   F-statistic:                    0.9595\n",
       "Date:                Sun, 05 Dec 2021   Prob (F-statistic):              0.419\n",
       "Time:                        23:52:46   Log-Likelihood:                 108.81\n",
       "No. Observations:                  53   AIC:                            -209.6\n",
       "Df Residuals:                      49   BIC:                            -201.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0084      0.006      1.417      0.163      -0.004       0.020\n",
       "SPY            0.4666      0.277      1.687      0.098      -0.089       1.023\n",
       "SPY_UP        -0.7821      0.629     -1.244      0.219      -2.045       0.481\n",
       "SPY_DOWN       1.2896      1.157      1.115      0.270      -1.036       3.615\n",
       "==============================================================================\n",
       "Omnibus:                       18.184   Durbin-Watson:                   1.923\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.179\n",
       "Skew:                          -0.980   Prob(JB):                     2.30e-08\n",
       "Kurtosis:                       6.477   Cond. No.                         276.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 0.03\n",
    "k2 = -k1\n",
    "\n",
    "exo = pd.concat([pd.Series(np.ones(len(ex2)), name=\"const\", index=ex2.index), ex2[\"SPY\"],\n",
    "                 ex2[\"SPY\"].apply(lambda x: max(x-k1, 0)).rename(\"SPY_UP\"),\n",
    "                 ex2[\"SPY\"].apply(lambda x: max(k2-x, 0)).rename(\"SPY_DOWN\")], axis=1)\n",
    "\n",
    "res = sm.OLS(ex2[\"net\"], exo).fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a286736-7973-4a81-acb5-69582d42140a",
   "metadata": {},
   "source": [
    "(b) Is LTCM long or short the call-like factor? And the put-like factor?\n",
    "\n",
    "pass\n",
    "\n",
    "(c) Which factor moves LTCM more, the call-like factor, or the put-like factor?\n",
    "\n",
    "pass\n",
    "\n",
    "(d) In the previous problem, you commented on whether LTCM is positively or negatively exposed to market volatility. Using this current regression, does this volatility exposure come more from being long the market’s upside? Short the market’s downside? Something else?\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9717fa1e-ee11-43b3-9eab-61d1a3abaa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in <fx.xlsx>.\n",
      "-------------------- Reading Sheets  --------------------\n",
      "Sheet 0: descriptions; shape=(9, 2)\n",
      "Sheet 1: risk-free rates; shape=(274, 6)\n",
      "Sheet 2: fx rates; shape=(274, 5)\n",
      "-------------------- Setting Indices --------------------\n",
      "-------------------- Checking Nulls  --------------------\n",
      "No nulls found :)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USD3M</th>\n",
       "      <td>3-Month LIBOR, USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBP3M</th>\n",
       "      <td>3-Month LIBOR, GBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR3M</th>\n",
       "      <td>3-Month LIBOR, EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF3M</th>\n",
       "      <td>3-Month LIBOR, CHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPY3M</th>\n",
       "      <td>3-Month LIBOR, JPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USUK</th>\n",
       "      <td>Spot FX, US per UK (GBP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USEU</th>\n",
       "      <td>Spot FX, US per EU (EUR)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USSZ</th>\n",
       "      <td>Spot FX, US per SZ (CHF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USJPY</th>\n",
       "      <td>Spot FX, US per JP (JPY)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ticker Description\n",
       "Unnamed: 0                          \n",
       "USD3M             3-Month LIBOR, USD\n",
       "GBP3M             3-Month LIBOR, GBP\n",
       "EUR3M             3-Month LIBOR, EUR\n",
       "CHF3M             3-Month LIBOR, CHF\n",
       "JPY3M             3-Month LIBOR, JPY\n",
       "USUK        Spot FX, US per UK (GBP)\n",
       "USEU        Spot FX, US per EU (EUR)\n",
       "USSZ        Spot FX, US per SZ (CHF)\n",
       "USJPY       Spot FX, US per JP (JPY)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USD3M</th>\n",
       "      <th>GBP3M</th>\n",
       "      <th>EUR3M</th>\n",
       "      <th>CHF3M</th>\n",
       "      <th>JPY3M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-31</th>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-02-28</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-04-30</th>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-05-31</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            USD3M  GBP3M   EUR3M   CHF3M   JPY3M\n",
       "DATE                                            \n",
       "1999-01-31 0.0041 0.0048  0.0026  0.0011  0.0004\n",
       "1999-02-28 0.0042 0.0045  0.0026  0.0011  0.0002\n",
       "1999-03-31 0.0042 0.0044  0.0025  0.0010  0.0002\n",
       "1999-04-30 0.0041 0.0044  0.0022  0.0008  0.0001\n",
       "1999-05-31 0.0042 0.0045  0.0021  0.0009  0.0001\n",
       "...           ...    ...     ...     ...     ...\n",
       "2021-06-30 0.0001 0.0001 -0.0005 -0.0006 -0.0001\n",
       "2021-07-31 0.0001 0.0001 -0.0005 -0.0006 -0.0001\n",
       "2021-08-31 0.0001 0.0001 -0.0005 -0.0006 -0.0001\n",
       "2021-09-30 0.0001 0.0001 -0.0005 -0.0006 -0.0001\n",
       "2021-10-31 0.0001 0.0002 -0.0005 -0.0006 -0.0001\n",
       "\n",
       "[274 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USUK</th>\n",
       "      <th>USEU</th>\n",
       "      <th>USSZ</th>\n",
       "      <th>USJP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-31</th>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>-0.3484</td>\n",
       "      <td>-4.7536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-02-28</th>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>-0.3712</td>\n",
       "      <td>-4.7766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>0.4787</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>-0.3904</td>\n",
       "      <td>-4.7743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-04-30</th>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>-0.4225</td>\n",
       "      <td>-4.7827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-05-31</th>\n",
       "      <td>0.4713</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>-0.4240</td>\n",
       "      <td>-4.7948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>0.3225</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>-4.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>0.3302</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>-4.6977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>-4.7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>0.2979</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>-4.7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>-4.7365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             USUK   USEU    USSZ    USJP\n",
       "DATE                                    \n",
       "1999-01-31 0.4982 0.1285 -0.3484 -4.7536\n",
       "1999-02-28 0.4717 0.0949 -0.3712 -4.7766\n",
       "1999-03-31 0.4787 0.0777 -0.3904 -4.7743\n",
       "1999-04-30 0.4753 0.0549 -0.4225 -4.7827\n",
       "1999-05-31 0.4713 0.0413 -0.4240 -4.7948\n",
       "...           ...    ...     ...     ...\n",
       "2021-06-30 0.3225 0.1696  0.0776 -4.7100\n",
       "2021-07-31 0.3302 0.1709  0.0986 -4.6977\n",
       "2021-08-31 0.3182 0.1655  0.0876 -4.7009\n",
       "2021-09-30 0.2979 0.1464  0.0684 -4.7140\n",
       "2021-10-31 0.3138 0.1443  0.0872 -4.7365\n",
       "\n",
       "[274 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fxxl = DataImport(\"fx.xlsx\", na_method=\"drop\")\n",
    "display(fxxl.sheets[0])\n",
    "rates = fxxl.sheets[1] / 12\n",
    "fx = fxxl.sheets[2]\n",
    "rates = np.log(rates+1)\n",
    "fx = np.log(fx)\n",
    "display(rates, fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6542d6e6-d738-438d-8d88-a0b90584afe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USUK</th>\n",
       "      <th>USEU</th>\n",
       "      <th>USSZ</th>\n",
       "      <th>USJP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-02-28</th>\n",
       "      <td>-0.0261</td>\n",
       "      <td>-0.0352</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>-0.0270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.0188</td>\n",
       "      <td>-0.0223</td>\n",
       "      <td>-0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-04-30</th>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0248</td>\n",
       "      <td>-0.0354</td>\n",
       "      <td>-0.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-05-31</th>\n",
       "      <td>-0.0038</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>-0.0162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-06-30</th>\n",
       "      <td>-0.0162</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>-0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>-0.0273</td>\n",
       "      <td>-0.0294</td>\n",
       "      <td>-0.0290</td>\n",
       "      <td>-0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>-0.0120</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.0117</td>\n",
       "      <td>-0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>-0.0204</td>\n",
       "      <td>-0.0197</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>-0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>0.0160</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>-0.0226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              USUK    USEU    USSZ    USJP\n",
       "DATE                                      \n",
       "1999-02-28 -0.0261 -0.0352 -0.0259 -0.0270\n",
       "1999-03-31  0.0073 -0.0188 -0.0223 -0.0017\n",
       "1999-04-30 -0.0031 -0.0248 -0.0354 -0.0124\n",
       "1999-05-31 -0.0038 -0.0156 -0.0049 -0.0162\n",
       "1999-06-30 -0.0162 -0.0130 -0.0213 -0.0049\n",
       "...            ...     ...     ...     ...\n",
       "2021-06-30 -0.0273 -0.0294 -0.0290 -0.0112\n",
       "2021-07-31  0.0077  0.0008  0.0202  0.0120\n",
       "2021-08-31 -0.0120 -0.0060 -0.0117 -0.0034\n",
       "2021-09-30 -0.0204 -0.0197 -0.0200 -0.0133\n",
       "2021-10-31  0.0160 -0.0027  0.0181 -0.0226\n",
       "\n",
       "[273 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dspot = fx - fx.shift(1)\n",
    "fore = dspot.add(rates[rates.columns[1:]].values).dropna()\n",
    "forex = fore.subtract(rates[\"USD3M\"], axis=0).dropna()\n",
    "display(forex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eceedd-733c-4e84-a0e6-58429ad5b7e7",
   "metadata": {},
   "source": [
    "# 3. The FX Carry Trade\n",
    "\n",
    "Find an Excel data file, “fx carry data.xlsx”. The file has two sets of data:\n",
    "\n",
    "• Risk-free rates across 5 currencies, as measured by annualized 3-month LIBOR rates.\n",
    "\n",
    "• Spot FX rates, as direct quotes to the USD. (Note that all currencies are quoted as USD per the foreign currency.)\n",
    "\n",
    "For use in the homework, note the following:\n",
    "\n",
    "• For risk-free rate data, rf,i , the rate is known and reported in the data at time t. Namely,\n",
    "any given date t in the data file is reporting both Si and rf,i .\n",
    "\n",
    "• The theory says to use log risk-free rates. You have the risk-free rate in levels: use the following\n",
    "equation to convert them:\n",
    "\n",
    "rf,i = ln(1 + rf,i ) t,t+1 t,t+1\n",
    "\n",
    "• The theory says to use log spot FX prices. You have the FX prices in levels, so directly take their logarithims:\n",
    "sit = ln(Sti)\n",
    "\n",
    "#### 1. The Static Carry Trade\n",
    "\n",
    "Define the log return of holding the foreign currency using log values of the risk-free rate and log values of the FX rates:\n",
    "\n",
    "ri ≡ si − si + rf,i t+1 t+1 t t,t+1\n",
    "\n",
    "Then the excess log return relative to USD, is expressed as\n",
    "\n",
    "For each foreign currency, i, calculate the excess log return series,  ̃rt+1. Report the following\n",
    "stats, (based on the excess log returns.) Annualize them.\n",
    "\n",
    "(a) mean\n",
    "\n",
    "(b) volatility\n",
    "\n",
    "(c) Sharpe ratio\n",
    "\n",
    "What differences do you see across currencies?\n",
    "\n",
    "All currencies have low mean, indicating relative stability with respect to one another. The European currencies move on a similar magnitude (~0.0035-0.0045) due to the exchange rate with dollars being relatively close to 1. EUR, JPY, and GBP have all weakened agains USD as indicated by the negative mean whereas CHF has strengthened. All currencies have annualized volatility of around 9%. JPY has weakened the most substantially compared with the other currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2989abd5-f93b-4be3-88bb-27542e00e22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1999-2021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Vol</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USEU</th>\n",
       "      <td>-0.0045</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>-0.0474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USJP</th>\n",
       "      <td>-0.0180</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>-0.1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USSZ</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USUK</th>\n",
       "      <td>-0.0033</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>-0.0385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year     1999-2021               \n",
       "measure       Mean    Vol  Sharpe\n",
       "variable                         \n",
       "USEU       -0.0045 0.0948 -0.0474\n",
       "USJP       -0.0180 0.0916 -0.1970\n",
       "USSZ        0.0040 0.0988  0.0407\n",
       "USUK       -0.0033 0.0864 -0.0385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = pivot_summaries(forex)\n",
    "display(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5bc7d-84d1-4ba4-884f-6bbe83838f86",
   "metadata": {},
   "source": [
    "#### 2. Implications for UIP:\n",
    "\n",
    "(a) Do any of these stats contradict the (log version) of Uncovered Interest Parity (UIP)?\n",
    "\n",
    "Uncovered interest rate parity states that\n",
    "\n",
    "$\\log(\\mathbb{E}_t[S_{t+1}]) - s_t = r^{f,\\text{REF}}_{t+1} - r^{f,\\text{QTE}}_{t+1}$\n",
    "\n",
    "Our foreign exchange return series rearranges the equation to\n",
    "\n",
    "$S_{t+1} - s_t - r^{f,\\text{REF}}_{t+1} + r^{f,\\text{QTE}}_{t+1} = 0$\n",
    "\n",
    "Therefore, considering that there are non-zero means for the forex return series, we observe a contradiction of Uncovered Interest Rate parity. However, it can also be argued that the volatility is significantly higher than the mean, and the slight deviation from the expected value of 0 is a matter of noise.\n",
    "\n",
    "(b) A long position in which foreign currency offered the best Sharpe ratio over the sample?\n",
    "\n",
    "CHF would have offered the best sharpe ratio by a significant margin.\n",
    "\n",
    "(c) Are there any foreign currencies for which a long position earned a negative excess return (in USD) over the sample?\n",
    "\n",
    "EUR, JPY, and GBP all returned negative within the sample, likely due to the US economic boom in the 1990's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eddfd6-4ef8-4096-8fd3-e0b5c13e856c",
   "metadata": {},
   "source": [
    "#### 3. Predicting FX\n",
    "\n",
    "For each foreign currency, test whether interest-rate differentials can predict growth in the\n",
    "foreign-exchange rate.1 Do this by estimating the following forecasting regression::\n",
    "\n",
    "where rf,i denotes the risk-free rate of currency i, and si denotes the FX rate for currency i.\n",
    "Again, note that both rf,$ and st are determined at time t. t,t+1\n",
    "\n",
    "(a) Make a table with columns corresponding to a different currency regression. Report the regression estimates αi and βi in the first two rows. Report the R2 stat in the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0cd9d27-aa19-4ca4-9006-09a121fecd96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plee/miniconda3/envs/finmath/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>rsq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USUK</th>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USEU</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>-1.3255</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USSZ</th>\n",
       "      <td>0.0462</td>\n",
       "      <td>-1.7743</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USJP</th>\n",
       "      <td>-0.0065</td>\n",
       "      <td>0.3845</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha    beta    rsq\n",
       "USUK -0.0061  0.4090 0.0003\n",
       "USEU  0.0076 -1.3255 0.0031\n",
       "USSZ  0.0462 -1.7743 0.0045\n",
       "USJP -0.0065  0.3845 0.0005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dspot.dropna(inplace=True)\n",
    "rates = rates.shift().dropna()\n",
    "diff = -rates.subtract(rates[\"USD3M\"], axis=0)\n",
    "\n",
    "curr = [\n",
    "    (\"GBP3M\", \"USUK\"),\n",
    "    (\"EUR3M\", \"USEU\"), \n",
    "    (\"CHF3M\", \"USSZ\"),\n",
    "    (\"JPY3M\", \"USJP\")\n",
    "]\n",
    "build_df = {\n",
    "    \"alpha\": [],\n",
    "    \"beta\": [],\n",
    "    \"rsq\": []\n",
    "}\n",
    "resses = []\n",
    "\n",
    "for t in curr:\n",
    "    exo = sm.add_constant(diff[t[0]].loc[dspot.index])\n",
    "    res = sm.OLS(dspot[t[1]], exo).fit()\n",
    "    build_df[\"alpha\"].append(res.params.values[0])\n",
    "    build_df[\"beta\"].append(res.params.values[1])\n",
    "    build_df[\"rsq\"].append(res.rsquared)\n",
    "    resses.append(res)\n",
    "\n",
    "rate_reg = pd.DataFrame(build_df, index=[c[1] for c in curr])\n",
    "rate_reg[\"alpha\"] *=12\n",
    "display(rate_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d16d5-2e60-4dfa-9cfe-1ee319274831",
   "metadata": {},
   "source": [
    "(b) Suppose the foreign risk-free rate increases relative to the US rate.\n",
    "\n",
    "i. For which foreign currencies would we predict a relative strengthening of the USD in the following period?\n",
    "\n",
    "The foreign risk free rate increasing decreases the exogenous variable. A relative strengthening of USD manifests in a negative value of the endogenous variable. Therefore, only JPY will yield such a result if the rate increase is large. However, GBP may also see relative strengthening if the rate increase is small enough to not overpower the regression intercept of -0.0007.\n",
    "\n",
    "ii. For which currencies would we predict relative weakening of the USD in the following period?\n",
    "\n",
    "EUR and CHF will certainly exhibit weakening of USD due to the regression yielding a positive return.\n",
    "\n",
    "iii. This FX predictability is strongest in the case of which foreign currency?\n",
    "\n",
    "The predictability is strongest in 1. CHF and 2. EUR due to relatively high $R^2$ statistics. GBP and JPY regressions hold very small predictive values by comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c3dc1-5ca3-4cc6-802c-3777d2cb42dd",
   "metadata": {},
   "source": [
    "#### 4. The Dynamic Carry Trade\n",
    "\n",
    "Use this to write  as a function of the interest-rate differential as well as α and β from this FX regression.\n",
    "\n",
    "Then use the definition of excess (log) returns on FX:\n",
    "\n",
    "(a) Use your regression estimates from Problem 3 along with the formula above to calculate the fraction of months for which the estimated FX risk premium positive. That is, for each i, calculate how often in the time-series we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a02d4b6-af96-4cc3-b3f1-218d32e35869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBP3M</th>\n",
       "      <th>EUR3M</th>\n",
       "      <th>CHF3M</th>\n",
       "      <th>JPY3M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-02-28</th>\n",
       "      <td>-0.0001</td>\n",
       "      <td>-0.0030</td>\n",
       "      <td>-0.0047</td>\n",
       "      <td>-0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0048</td>\n",
       "      <td>-0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-04-30</th>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0048</td>\n",
       "      <td>-0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-05-31</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>-0.0054</td>\n",
       "      <td>-0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-06-30</th>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>-0.0055</td>\n",
       "      <td>-0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31</th>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GBP3M   EUR3M   CHF3M   JPY3M\n",
       "DATE                                      \n",
       "1999-02-28 -0.0001 -0.0030 -0.0047 -0.0028\n",
       "1999-03-31 -0.0003 -0.0031 -0.0048 -0.0030\n",
       "1999-04-30 -0.0004 -0.0033 -0.0048 -0.0030\n",
       "1999-05-31 -0.0003 -0.0040 -0.0054 -0.0030\n",
       "1999-06-30 -0.0004 -0.0042 -0.0055 -0.0031\n",
       "...            ...     ...     ...     ...\n",
       "2021-06-30 -0.0005 -0.0007  0.0018 -0.0007\n",
       "2021-07-31 -0.0005 -0.0007  0.0018 -0.0007\n",
       "2021-08-31 -0.0005 -0.0007  0.0018 -0.0007\n",
       "2021-09-30 -0.0005 -0.0007  0.0018 -0.0007\n",
       "2021-10-31 -0.0005 -0.0007  0.0018 -0.0007\n",
       "\n",
       "[273 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_tilde = diff.iloc[:, 1:].multiply((rate_reg[\"beta\"]-1).values, axis=1) \\\n",
    "                          .add(rate_reg[\"alpha\"].values/12, axis=1)\n",
    "display(r_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcadc77-78d9-4b6a-bdf7-659c5cbe0b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBP3M   0.2454\n",
       "EUR3M   0.5128\n",
       "CHF3M   0.6190\n",
       "JPY3M   0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r_tilde>0).sum() / len(r_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2d9b4-16e6-4d29-84b4-4170540cd1d6",
   "metadata": {},
   "source": [
    "(b) Which currencies most consistently have a positive FX risk premium? And for which\n",
    "currencies does the FX risk premium most often go negative?\n",
    "\n",
    "CHF has the most positive risk premium, JPY's risk premium is predicted to be 0 within all datapoints.\n",
    "\n",
    "(c) Explain how we could use these conditional risk premia to improve the static carry trade returns calculated in Problem 1.\n",
    "\n",
    "The predicted risk premia can be used to actively trade the carry, improving returns over passively holding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f2239-4f07-48d1-bf22-ba602a52ce50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
